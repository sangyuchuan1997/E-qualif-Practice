{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1UKgUQqlZpA_MfNCfGC4cdvaEkVWI4gIe","timestamp":1645494745515}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"oOzCIgNTGt7b"},"source":["#修了課題DEMO①　Titanic"]},{"cell_type":"markdown","source":["##はじめに\n","この修了課題では、Titanic号の乗客の情報を利用して、\n","\n","テストデータで用意した乗客が生き残れるかを予測します。\n","\n","今回はDEMOとして、２層のニューラルネットワークを用いて\n","\n","クラス(pclass)・性別(sex)・乗船港(emberked)の３つの要素を取り上げながら、\n","\n","学習をさせてみましょう。"],"metadata":{"id":"4AXJM2GYKAS9"}},{"cell_type":"markdown","source":["##作成までの流れ\n","大まかな流れとして\n","1. データのダウンロードと成形\n","\n","   データダウンロードしてそのまま活用するのは困難です。\n","   モデルが学習できるよう、カテゴリ変数に置き換えたり、\n","   欠損値を補完したりなど、成形する必要があります。\n","2. モデルの構築\n","\n","   学習を行うモデルのアルゴリズムを理解して、コードを作成します。\n","\n","3. 学習と結果\n","\n","   学習を行い結果を確認してみます。\n","   精度が目標まで達したら、提出用のデータを作成します。"],"metadata":{"id":"QVOc238jnrhX"}},{"cell_type":"markdown","source":["#1.データのダウンロードと成形"],"metadata":{"id":"OBy0sscFp2eZ"}},{"cell_type":"markdown","metadata":{"id":"b6CAFkUEut_D"},"source":["## データのダウンロード"]},{"cell_type":"code","metadata":{"id":"HQPfHUkvwjQE"},"source":["import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fxLXrmA33wXy"},"source":["# 学習用のデータのダウンロード\n","!wget 'https://drive.google.com/uc?export=download&id=1-12Pg5IsjNAEbgk7G4a2WqFaOhpYmbyJ' -O titanic_train.csv\n","# 検証用のデータのダウンロード\n","!wget 'https://drive.google.com/uc?export=download&id=1jmzmYNPRWUGLcHeqhcwKTGlb_d2Rzn4Y' -O titanic_validation.csv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"diXNDb3G32d2"},"source":["# 学習用データ\n","train_df = pd.read_csv('titanic_train.csv', index_col=0)\n","display(train_df.head(3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CFXh3gzb5foY"},"source":["# 検証用データ\n","val_df = pd.read_csv('titanic_validation.csv', index_col=0)\n","display(val_df.head(3))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["学習用データと検証用データの情報を確認してみましょう。\n","\n","欠損値がないようにみえますが、？で埋められているため\n","\n","np.nanで置き換えてあげましょう。\n","\n","また、\"Dtype\"がint64のものは全てのデータがint64型を示していますが、\n","\n","\"Dtype\"がobjectのものは、データの中身に複数の型が紛れています。\n","\n","もし、\"Dtype\"がobjectになっているデータも使用したいときは\n","\n","型を統一するように処理をかける必要があることに注意しましょう。\n"],"metadata":{"id":"RqkW7yE3MaDm"}},{"cell_type":"code","metadata":{"id":"n5d6USZdssqM"},"source":["train_df = train_df.replace('?', np.nan)\n","val_df = val_df.replace('?', np.nan)\n","train_df.info()\n","val_df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QRTKLu_Gyse6"},"source":["## データの成形\n","\n","今回使用する２層のニューラルネットワークのために必要な処理を施していきます。"]},{"cell_type":"code","metadata":{"id":"tGB1LVm80Knm"},"source":["#学習用データと検証用データの２つを繋げて、同時に処理できるようにしておく\n","dataset = [train_df, val_df]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D8QhszIUqtNH"},"source":["## 生存と関係性の強い項目の確認\n","\n","今回取り上げる\n","クラス(pclass)・性別(sex)・乗船港(emberked)について\n","\n","どの程度生存に関連しているかを確かめてみましょう。"]},{"cell_type":"code","metadata":{"id":"9l2CGsobrISi"},"source":["# クラス pclass\n","train_df[['pclass', 'survived']].groupby(['pclass'], as_index=False).mean().sort_values(by='survived', ascending=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SrKrP8pRq1ih"},"source":["# 性別 sex\n","train_df[[\"sex\", \"survived\"]].groupby(['sex'], as_index=False).mean().sort_values(by='survived', ascending=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nrFBlsOmv_eU"},"source":["# 乗船港 emberked\n","train_df[[\"embarked\", \"survived\"]].groupby(['embarked'], as_index=False).mean().sort_values(by='survived', ascending=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Y4jPJJzv35s"},"source":["# 上記の3変数で予測するので、１つにまとめる\n","columns = ['pclass','sex','embarked', ]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5MzRYawnqpoD"},"source":["## 欠損値処理\n","\n","ここで一度、学習用データと検証用データを確認してみましょう。\n","\n","すると、検証用データの「emberked」には値が？になっているものがあります。\n","\n","先ほど、データをダウンロードしたときに「val_df.replace('?', np.nan)」としているので、\n","\n","その欠損値をさらに最頻値に置き換えてみます。"]},{"cell_type":"code","metadata":{"id":"tBiz9fGDxLTE"},"source":["#欠損値の部分を削除する\n","freq_port = train_df.embarked.dropna().mode()[0]\n","#空いた部分に最頻値を入れて埋める\n","train_df['embarked'].fillna(freq_port, inplace=True)\n","val_df['embarked'].fillna(freq_port, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rk1s21sGq3-d"},"source":["## カテゴリーデータの処理"]},{"cell_type":"markdown","source":["乗船港と性別は文字で登録されているので、\n","\n","数値に置き換えてみましょう。\n","\n","それぞれにint型でカテゴリー変数に変えてみます。"],"metadata":{"id":"-ad1m8BvRwoI"}},{"cell_type":"code","metadata":{"id":"7nxvkGtwq3Z9"},"source":["for data in dataset:\n","  data['embarked'] = data['embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PxTEPts5u05a"},"source":["for data in dataset:\n","    data['sex'] = data['sex'].map( {'female': 1, 'male': 0} ).astype(int)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EszBPYFh29Ed"},"source":["## データの分割\n","学習用データと検証用データの中にはそれぞれ\n","\n","'pclass','sex','embarked','survived'が格納されています。\n","\n","生存者予測を学習するので、'pclass','sex','embarked'と'survived'に分けましょう。"]},{"cell_type":"code","metadata":{"id":"8wrfObOd1dtK"},"source":["X_train = train_df[['pclass','sex','embarked']]\n","y_train = train_df['survived']\n","X_val = val_df[['pclass','sex','embarked']]\n","y_val = val_df['survived']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2.モデルの構築"],"metadata":{"id":"oaWNFvmdqJiP"}},{"cell_type":"markdown","metadata":{"id":"uA278SMv6Yay"},"source":["## NNの構築\n","\n","損失関数、活性化関数、ニューラルネットワークを構築します。\n","\n","損失関数はMSE、活性化関数はシグモイド関数、\n","\n","ネットワークは２層のニューラルネットワークになるように作っていきます。"]},{"cell_type":"code","metadata":{"id":"HpFP76tNw7cg"},"source":["# バッチ版mse\n","def rmse(y, t):\n","    delta = 1e-7\n","    if y.ndim == 1:\n","        t = t.reshape(1, t.size)\n","        y = y.reshape(1, y.size)\n","\n","    mini_batch = y.shape[0]\n","    t = t.astype(int)\n","    return np.sqrt(np.sum((y - t)**2) / mini_batch)\n","\n","# 活性化関数\n","# シグモイド関数\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def deriv_sigmoid(x):\n","    return (1 - sigmoid(x)) * sigmoid(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ctf1KlsxCFu"},"source":["# 2層のニューラルネットワーク\n","class TwoLayerNet:\n","\n","    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n","\n","        # 重みの初期化\n","        self.params = {}\n","        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n","        self.params['b1'] = np.zeros(hidden_size)\n","        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n","        self.params['b2'] = np.zeros(output_size)\n","\n","    def predict(self, x):\n","        W1, W2 = self.params['W1'], self.params['W2']\n","        b1, b2 = self.params['b1'], self.params['b2']\n","\n","        # forward\n","        u1 = np.dot(x, W1) + b1\n","        z1 = sigmoid(u1)\n","        u2 = np.dot(z1, W2) + b2\n","        y = sigmoid(u2)\n","\n","        return y\n","\n","    # x:入力データ, t:教師データ\n","    def loss(self, x, t):\n","        y = self.predict(x)\n","\n","        return rmse(y, t)\n","\n","    def accuracy(self, x, t):\n","        y = self.predict(x)\n","        y = np.where(y >= 0.5, 1, 0)\n","        #y = np.argmax(y, axis=1)\n","        #t = np.argmax(t, axis=1)\n","\n","        accuracy = np.sum(y == t) / float(x.shape[0])\n","        return accuracy\n","\n","    # 数値計算で勾配を求めると計算時間がかかるため、逆伝播法をはじめから実装する\n","    def gradient(self, x, t):\n","        W1, W2 = self.params['W1'], self.params['W2']\n","        b1, b2 = self.params['b1'], self.params['b2']\n","        grads = {}\n","\n","        batch_num = x.shape[0]\n","\n","        # forward\n","        u1 = np.dot(x, W1) + b1\n","        z1 = sigmoid(u1)\n","        u2 = np.dot(z1, W2) + b2\n","        y = sigmoid(u2)\n","\n","        # backward\n","        dy = (y - t) / batch_num\n","        grads['W2'] = np.dot(z1.T, dy)\n","        grads['b2'] = np.sum(dy, axis=0)\n","\n","        du1 = np.dot(dy, W2.T)\n","        dz1 = deriv_sigmoid(u1) * du1\n","        grads['W1'] = np.dot(x.T, dz1)\n","        grads['b1'] = np.sum(dz1, axis=0)\n","\n","        return grads"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PWKd1MDpxG0_"},"source":["# ３変数で予測するため、入力層のサイズは３\n","# 二値分類のため、出力層のサイズは１\n","network = TwoLayerNet(input_size=3, hidden_size=100, output_size=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["次にハイパーパラメータを設定します。\n","\n","エポック数や学習率は値によって学習の精度が変わりますので、\n","\n","いくつか試してみましょう。\n","\n","今回はDEMOとして以下の値を設定しました。"],"metadata":{"id":"7caqeDm1TjHm"}},{"cell_type":"code","metadata":{"id":"mymBiRhLKwUF"},"source":["epoch = 1000\n","train_size = X_train.shape[0]\n","mini_batch = 20\n","lr = 0.01"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"deT1GHJ7KwUH"},"source":["#lossの値とacc(精度)を格納する\n","train_loss_list = []\n","train_acc_list = []\n","val_acc_list = []\n","\n","# 1エポックあたりの繰り返し数を設定する\n","iter_per_epoch = max(train_size / mini_batch, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#3.学習から提出まで"],"metadata":{"id":"E5vravpqnUsd"}},{"cell_type":"markdown","source":["##学習"],"metadata":{"id":"rA1jL-2XupC6"}},{"cell_type":"code","metadata":{"id":"IKZGgdR0KwUK"},"source":["for i in range(epoch):\n","    # ミニバッチの取得を行う\n","    batch_mask = np.random.choice(train_size, mini_batch)\n","    x_batch = np.array(X_train.iloc[batch_mask])\n","    y_batch = np.array(y_train.iloc[batch_mask])[..., np.newaxis]\n","\n","    # 誤差逆伝播法によって勾配を求める\n","    grad = network.gradient(x_batch, y_batch)\n","\n","    # パラメータの更新をする\n","    for key in ('W1', 'b1', 'W2', 'b2'):\n","        network.params[key] -= lr * grad[key]\n","\n","    # 学習経過を記録する\n","    loss = network.loss(x_batch, y_batch)\n","    train_loss_list.append(loss)\n","\n","    # 1エポックごとに認識精度を計算する\n","    if i % iter_per_epoch == 0:\n","        train_acc = network.accuracy(np.array(X_train), np.array(y_train)[..., np.newaxis])\n","        val_acc = network.accuracy(np.array(X_val), np.array(y_val)[..., np.newaxis])\n","        train_acc_list.append(train_acc)\n","        val_acc_list.append(val_acc)\n","        print(\"train acc, val acc | \" + str(train_acc) + \", \" + str(val_acc))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6WY8kE1957t3"},"source":["import matplotlib.pyplot as plt\n","\n","markers = {'train': 'o', 'test': 's'}\n","x = np.arange(len(train_acc_list))\n","plt.plot(x, train_acc_list, label='train acc')\n","plt.plot(x, val_acc_list, label='val acc', linestyle='--')\n","plt.xlabel(\"epoches\")\n","plt.ylabel('accuracy')\n","plt.ylim(0, 1.0)\n","plt.legend(loc='lower right')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["今回の精度は約62％になりました。このモデルの仕様では目標の精度には達していませんね。\n","\n","２層のニューラルネットワークでは、思うように精度が出ないようです。\n","\n","モデルをより複雑なものにすることのほかにも\n","\n","エポック数を増やしてみたり、予測する要素を変更するなどの処理を行ってみると\n","\n","精度が向上するかもしれません。"],"metadata":{"id":"1Nj6ktMkUolP"}},{"cell_type":"markdown","metadata":{"id":"Hs_p7w3NpSR1"},"source":["## （参考）提出用データの作成の仕方\n","参考として、今回学習した２層のニューラルネットワークモデルが\n","\n","テスト用のデータを予測して、結果をcsvファイルとして出力するまでを\n","\n","掲載してみました。\n","\n","このcsvファイルを「修了課題提出用サイト」にアップロードすると結果を確認することができます。"]},{"cell_type":"code","metadata":{"id":"Gj0iLNBqqO0n"},"source":["# 提出用のデータをダウンロード\n","!wget 'https://drive.google.com/uc?export=download&id=1-1KX2NQmwUOXAstOE7c2INC1rRMNABVZ' -O titanic_test_x.csv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R8xxty43q48D"},"source":["X_test = pd.read_csv('titanic_test_x.csv', index_col=0)\n","X_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E6Y7t9gUpScg"},"source":["# Demoで行った処理をテスト用のデータにも行う\n","X_test = X_test.replace('?', np.nan)\n","X_test['embarked'].fillna(freq_port, inplace=True)\n","X_test['embarked'] = X_test['embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n","X_test['sex'] = X_test['sex'].map( {'female': 1, 'male': 0} ).astype(int)\n","X_test = X_test[['pclass','sex','embarked']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GspLRWTVrWH1"},"source":["# 学習させたモデルで予測する\n","y_pred = network.predict(X_test)\n","# このままだと確率値がでてしまうので、確率に基づいて最終的な判定値に変換する\n","y_pred = np.where(y_pred >= 0.5, 1, 0)\n","# pandasのDataFrame形式に変換し、CSV出力する\n","y_pred = pd.DataFrame(y_pred, columns=['survived'])\n","# csv形式で提出する\n","y_pred.to_csv('y_pred.csv')\n","y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"opV33il43EyV"},"source":["## （参考）sk-learnを利用した機械学習モデルを用いた予測"]},{"cell_type":"code","metadata":{"id":"Jx4yJuRH3tp3"},"source":["# ロジスティック回帰\n","from sklearn.linear_model import LogisticRegression\n","logreg = LogisticRegression()\n","logreg.fit(X_train, y_train)\n","\n","acc_log = round(logreg.score(X_train, y_train) * 100, 2)\n","acc_log_val = round(logreg.score(X_val, y_val) * 100, 2)\n","print('学習精度:', acc_log)\n","print('検証精度:', acc_log_val)\n","\n","# 予測する際\n","Y_pred = logreg.predict(X_test)"],"execution_count":null,"outputs":[]}]}