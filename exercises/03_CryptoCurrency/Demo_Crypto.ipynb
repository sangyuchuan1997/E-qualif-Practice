{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7kxEBr-lv_T"
   },
   "source": [
    "# 修了課題DEMO③ 仮想通貨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5emUdH59ik5M"
   },
   "source": [
    "[JDLAが策定しているバージョン](https://www.jdla.org/certificate/engineer/)に合わせるために、以下のセルの実行をお願いします．\n",
    "\n",
    "（#コメントアウト されているものは必要ありません）\n",
    "\n",
    "また実行完了後に「ランタイムの再起動」をして下さい．\n",
    "\n",
    "（以下のセルの実行は、最初にしていただければ、以降必要ありません．）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RKhI4UZzieRG"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip uninstall matplotlib -y\n",
    "!pip install matplotlib==3.7.1\n",
    "\n",
    "# !pip uninstall opencv-python -y\n",
    "# !pip install opencv-python==4.7.0.72\n",
    "\n",
    "# !pip uninstall torch -y\n",
    "# !pip install torch==2.0.1\n",
    "\n",
    "# !pip uninstall torchvision -y\n",
    "# !pip install torchvision==0.15.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzQwk077sEfv"
   },
   "source": [
    "##はじめに\n",
    "この修了課題では、仮想通貨の情報を利用して、\n",
    "\n",
    "未来の仮想通貨の価格予想を行うものです。\n",
    "\n",
    "今回はDEMOとして、RNN(再帰型ニューラルネットワーク)を用いて学習をさせてみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVOc238jnrhX"
   },
   "source": [
    "##作成までの流れ\n",
    "大まかな流れとして\n",
    "1. データのダウンロードと成形\n",
    "\n",
    "   データダウンロードしてそのまま活用するのは困難です。\n",
    "   モデルが学習できるよう、カテゴリ変数に置き換えたり、\n",
    "   欠損値を補完したりなど、成形する必要があります。\n",
    "2. モデルの構築\n",
    "\n",
    "   学習を行うモデルのアルゴリズムを理解して、コードを作成します。\n",
    "\n",
    "3. 学習と結果\n",
    "\n",
    "   学習を行い結果を確認してみます。\n",
    "   精度が目標まで達したら、提出用のデータを作成します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBy0sscFp2eZ"
   },
   "source": [
    "#1.データのダウンロードと成形"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6CAFkUEut_D"
   },
   "source": [
    "## データのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "su_G_--CWtcx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U8cWndIcl5Lj"
   },
   "outputs": [],
   "source": [
    "# 学習データのダウンロード\n",
    "!wget 'https://drive.google.com/uc?export=download&id=1kUfPb8qikA8rdQ26iVUxpod2Qjw3ct_O' -O crypto_train.csv\n",
    "\n",
    "# テストデータのダウンロード\n",
    "!wget 'https://drive.google.com/uc?export=download&id=1VhzCcjNSDxGRG86Za653zHHpjVCdSPD3' -O crypto_test_x.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vccbxcBcZqNT"
   },
   "outputs": [],
   "source": [
    "# 学習データの確認\n",
    "train = pd.read_csv('crypto_train.csv', index_col=0)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRTKLu_Gyse6"
   },
   "source": [
    "## データの成形\n",
    "\n",
    "今回使用するRNNのために必要な処理を施していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlWfOIIaMdpK"
   },
   "outputs": [],
   "source": [
    "# 正規化処理\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler = scaler.fit(train.values)\n",
    "\n",
    "# 正規化する\n",
    "s_train = scaler.transform(train)\n",
    "# 元の値に戻す場合\n",
    "inv_train = scaler.inverse_transform(s_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xE8RD1HXlqh"
   },
   "outputs": [],
   "source": [
    "# データの形状確認\n",
    "print(s_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "elGnEnPIe0VK"
   },
   "outputs": [],
   "source": [
    "# シーケンスデータの教師ありデータを作成する\n",
    "def make_seq(data, seq_len=6):\n",
    "    X = data[:, 0:seq_len]\n",
    "    X = np.expand_dims(X, axis=2)\n",
    "    Y = data[:, seq_len:]\n",
    "    return X, Y\n",
    "\n",
    "X, Y = make_seq(s_train)\n",
    "\n",
    "def train_val_split(X, Y, val_rate):\n",
    "  rate = int(X.shape[0]*(1-val_rate))\n",
    "  train_X, train_Y, val_X, val_Y = X[:rate], Y[:rate], X[rate:], Y[rate:]\n",
    "  return train_X, train_Y, val_X, val_Y\n",
    "\n",
    "train_X, train_Y, val_X, val_Y = train_val_split(X, Y, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PCRXVl89vUm"
   },
   "outputs": [],
   "source": [
    "# データの形状確認\n",
    "print('train_X:', train_X.shape)\n",
    "print('train_Y:', train_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oaWNFvmdqJiP"
   },
   "source": [
    "# 2.モデルの構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Q49blPo5DIO"
   },
   "source": [
    "## モデル容量の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bl1BceHHkm6s"
   },
   "outputs": [],
   "source": [
    "# 入力データのひとつあたりの次元\n",
    "input_size = 1\n",
    "# モデル容量の定義\n",
    "hidden_dim = 10\n",
    "# 出力データのひとつあたりの次元\n",
    "output_dim = input_size\n",
    "U = (np.random.randn(input_size, hidden_dim)/np.sqrt(hidden_dim)).astype('f')\n",
    "W = (np.random.randn(hidden_dim, hidden_dim)/np.sqrt(hidden_dim)).astype('f')\n",
    "b = np.zeros(hidden_dim).astype('f')\n",
    "V = (np.random.randn(hidden_dim, output_dim)/np.sqrt(hidden_dim)).astype('f')\n",
    "c = np.zeros(output_dim).astype('f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-GSEQCjVs_qT"
   },
   "source": [
    "#3.精度確認から提出まで"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_MRbDMApuegU"
   },
   "source": [
    "##学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EEBIEzlngldx"
   },
   "outputs": [],
   "source": [
    "# 学習のハイパーパラメータ\n",
    "epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "# 勾配爆発を防ぐために勾配クリッピングを行う\n",
    "min_clip_value = -10\n",
    "max_clip_value = 10\n",
    "\n",
    "# データの設定\n",
    "X = train_X\n",
    "Y = train_Y\n",
    "\n",
    "# 勾配クリッピングの関数定義\n",
    "def clip_gradient(matrix):\n",
    "    if np.any(matrix > max_clip_value):\n",
    "        matrix[matrix > max_clip_value] = max_clip_value\n",
    "    if np.any(matrix < min_clip_value):\n",
    "        matrix[matrix < min_clip_value] = min_clip_value\n",
    "    return matrix\n",
    "\n",
    "# 学習\n",
    "for epoch in range(epochs):\n",
    "    batch_size = X.shape[0]\n",
    "    prev_ss = {}\n",
    "    prev_s = np.zeros((batch_size, hidden_dim))\n",
    "\n",
    "    # 順伝播\n",
    "    for i in range(X.shape[1]):\n",
    "        new_input = X[:,  i]\n",
    "        mulu = np.dot(new_input, U)\n",
    "        mulw = np.dot(prev_s, W)\n",
    "        add = mulw + mulu + b\n",
    "        prev_s = np.tanh(add)\n",
    "        prev_ss[str(i)] = prev_s\n",
    "\n",
    "    # 予測と損失計算\n",
    "    pred = np.dot(prev_s, V) + c\n",
    "    per_loss = (Y-pred)**2/2\n",
    "    loss = np.sum(per_loss)/(batch_size)\n",
    "    print('epoch:', epoch+1, 'Loss:', loss)\n",
    "\n",
    "    # 逆伝播\n",
    "    e_o = pred-Y\n",
    "\n",
    "    dV = np.dot(pred.T, e_o)\n",
    "    dc = np.sum(e_o)/batch_size\n",
    "\n",
    "    dU = 0\n",
    "    dW = 0\n",
    "    db = 0\n",
    "\n",
    "    for t in range(X.shape[1]):\n",
    "        e_h = (1 - prev_s[t]**2) * np.dot(e_o, V.T)\n",
    "        new_input = X[:,  i]\n",
    "        # new_input = np.expand_dims(X[:,  i], axis=1)\n",
    "\n",
    "        if t==0:\n",
    "          dU = np.dot( new_input.T, e_h)\n",
    "          dW = np.dot(np.zeros((batch_size, hidden_dim)).T, e_h)\n",
    "          db = np.sum(e_h, axis=0)\n",
    "        else:\n",
    "          dU += np.dot(new_input.T, e_h)\n",
    "          dW += np.dot(prev_ss[str(t-1)].T, e_h)\n",
    "          db += np.sum(e_h, axis=0)/batch_size\n",
    "\n",
    "    # 勾配クリッピングの適用\n",
    "    dU = clip_gradient(dU)\n",
    "    dV = clip_gradient(dV)\n",
    "    dW = clip_gradient(dW)\n",
    "\n",
    "    # 重みを更新\n",
    "    U -= learning_rate * dU\n",
    "    V -= learning_rate * dV\n",
    "    W -= learning_rate * dW\n",
    "    b -= learning_rate * db\n",
    "    c -= learning_rate * dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNvDz7SUjNWF"
   },
   "outputs": [],
   "source": [
    "# 検証データで精度を確認する\n",
    "X = val_X\n",
    "Y = val_Y\n",
    "\n",
    "# 検証データの予測\n",
    "batch_size = X.shape[0]\n",
    "prev_s = np.zeros((batch_size, hidden_dim))\n",
    "\n",
    "# ネットワークを通して順伝播\n",
    "for i in range(X.shape[1]):\n",
    "    new_input = X[:,  i]\n",
    "    mulu = np.dot(new_input, U)\n",
    "    mulw = np.dot(prev_s, W)\n",
    "    add = mulw + mulu + b\n",
    "    prev_s = np.tanh(add)\n",
    "    prev_ss[str(i)] = prev_s\n",
    "\n",
    "# 出力層からの予測値\n",
    "pred = np.dot(prev_s, V) + c\n",
    "\n",
    "# スケーラーを使用して、標準化されたデータを元のスケールに戻す\n",
    "scaler = scaler.fit(train.values.reshape(-1, 1))\n",
    "Y = scaler.inverse_transform(Y)\n",
    "pred = scaler.inverse_transform(pred)\n",
    "\n",
    "# sklearnのmean_squared_error関数を使用してRMSEを計算\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "# 平均二乗誤差の平方根（RMSE）を計算\n",
    "rmse = math.sqrt(mean_squared_error(Y, pred))\n",
    "print('検証RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUBOwVfTjTPm"
   },
   "outputs": [],
   "source": [
    "plt.plot(Y[:])\n",
    "plt.plot(pred[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iT1z33-6u_Wk"
   },
   "source": [
    "今回の検証RMSEの値を確認すると、このモデルの仕様では目標の精度には達していないことが分かります。\n",
    "\n",
    "他のライブラリをインポートして、より精度が高くなるようなモデルを構築してみると\n",
    "\n",
    "精度が向上するかもしれません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qci71E7nGzP"
   },
   "source": [
    "## テストデータに対して予測値を出力する\n",
    "今回学習したRNNが\n",
    "\n",
    "テスト用のデータを予測して、結果をcsvファイルとして出力するまでを\n",
    "\n",
    "掲載してみました。\n",
    "\n",
    "このcsvファイルを「修了課題提出用サイト」にアップロードすると結果を確認することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ICyCFKLEumU"
   },
   "outputs": [],
   "source": [
    "# テストデータの確認\n",
    "test_x = pd.read_csv('crypto_test_x.csv', index_col=0)\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Jy9ePzEnGrs"
   },
   "outputs": [],
   "source": [
    "# テストデータも正規化する\n",
    "scaler = scaler.fit(test_x)\n",
    "s_test_x = scaler.transform(test_x)\n",
    "\n",
    "# データ形式をモデルに対して適正化する\n",
    "s_test_x = np.expand_dims(s_test_x, axis=2)\n",
    "\n",
    "# 検証データで精度を確認する\n",
    "X = s_test_x\n",
    "\n",
    "# 検証データの予測\n",
    "batch_size = X.shape[0]\n",
    "prev_s = np.zeros((batch_size, hidden_dim))\n",
    "for i in range(X.shape[1]):\n",
    "    new_input = X[:,  i]\n",
    "    mulu = np.dot(new_input, U)\n",
    "    mulw = np.dot(prev_s, W)\n",
    "    add = mulw + mulu + b\n",
    "    prev_s = np.tanh(add)\n",
    "    prev_ss[str(i)] = prev_s\n",
    "pred = np.dot(prev_s, V) + c\n",
    "\n",
    "# もとに戻した値\n",
    "scaler = scaler.fit(test_x.values.reshape(-1, 1))\n",
    "inv_pred = scaler.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLRnPqkdrgjD"
   },
   "outputs": [],
   "source": [
    "# 予測した値を出力する\n",
    "pred = pd.DataFrame(inv_pred, columns=['Sun'])\n",
    "pred.to_csv('crypto_pred.csv')\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1ukX5qkGqlYKZH8f58w5Yqw5DsSLGg6eY",
     "timestamp": 1645502283927
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
