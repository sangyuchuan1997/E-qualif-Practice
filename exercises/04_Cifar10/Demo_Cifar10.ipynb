{"cells":[{"cell_type":"markdown","metadata":{"id":"MpWPASHUaE8I"},"source":["# 修了課題DEMO④　CIFAR10\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YVDhKG_raLJq"},"source":["##はじめに\n","この修了課題では、Pytorchを使って「CIFAR10」という画像データセットの分類を行っていきます。  \n","今回使用するネットワーク構成は\n","    \n","    conv2d - relu - MaxPool2d -\n","    conv2d - relu - MaxPool2d -\n","    flatten -\n","    Linear - relu -\n","    Linear - relu - Linear\n","上記のようなCNNとなっています。  \n","ここで、viewとはサイズを１度調整するコマンドのことで、各要素の値そのものに変化はありません。  \n","また、Linearは線形結合を表しています。\n"]},{"cell_type":"markdown","metadata":{"id":"QVOc238jnrhX"},"source":["##作成までの流れ\n","大まかな流れとして\n","1. データのダウンロードと正規化  \n","   torchvisionというライブラリを使用して、CIFAR10の訓練用のデータ、テスト用のデータをダウンロードします。  \n","   また、ダウンロードした画像に対して正規化を行います。\n","\n","2. モデルの構築  \n","   学習を行うモデルの各層の役割を理解して、構築します。\n","\n","3. 損失関数などの設定  \n","   学習を行うのに必要な損失関数などの設定を行います。\n","\n","4. 学習と結果  \n","   訓練データで学習を行い、どのくらいの精度があるのかを、テスト用データを使って確認します。"]},{"cell_type":"markdown","metadata":{"id":"El2HCYFQLPCk"},"source":["##必要なライブラリーのインポートとGoogleDriveへの接続"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ttDjTe5Tg29q"},"outputs":[],"source":["#GoogleDriveへの接続を行う\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lFzORB9GKRT_"},"outputs":[],"source":["#必要なライブラリーのインポート\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","#ダウンロードに必要なライブラリーのインポート\n","import pickle\n","from PIL import Image\n","import os"]},{"cell_type":"markdown","metadata":{"id":"OBy0sscFp2eZ"},"source":["#1.データのダウンロードと正規化"]},{"cell_type":"markdown","metadata":{"id":"Vuqdr3mXMJ5K"},"source":["## データのダウンロード\n","\n","今回使用するデータを「wget」コマンドでダウンロードします。  \n","ダウンロードしたデータを直列に配置し、画像に変換する処理を行っていますが、  \n","今回はモデルの作成と学習が目的ですので、気にせず実行してください。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rTkCC2KOoHgH"},"outputs":[],"source":["!wget 'https://drive.google.com/uc?export=download&id=15kspx4XmoR5Kh1fKkdxjjPcn_Y8tkaP3' -O train.pickle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R6ftoubsIVlN"},"outputs":[],"source":["!wget 'https://drive.google.com/uc?export=download&id=1-QKklgEpROkVIUnaLQ9dKgfCK_mp78xN' -O val.pickle"]},{"cell_type":"markdown","metadata":{"id":"ZNslVUytQYHm"},"source":["下のセルで画像ファイルとして保存する処理を行っています。  \n","実行に平均1分程度かかりますが、データのダウンロードが完了します。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sx_K_cnkIvqf"},"outputs":[],"source":["# バイナリファイルを読み込んでから、画像データに変換処理を行う。\n","def parse_pickle(rawdata, dataset_name):\n","    for i in range(10):\n","        dir = dataset_name + \"/\" + f\"{i:02d}\"\n","        if not os.path.exists(dir):\n","            os.makedirs(dir)\n","    m = len(rawdata[\"data\"])\n","    for i in range(m):\n","        filename = f'{i}.png'\n","        label = rawdata[\"label\"][i]\n","        data = rawdata[\"data\"][i]\n","        data = data.reshape(3, 32, 32)\n","        data = np.swapaxes(data, 0, 2)\n","        data = np.swapaxes(data, 0, 1)\n","        with Image.fromarray(data) as img:\n","            img.save(f\"{dataset_name}/{label:02d}/{filename}\")\n","\n","train = {'label':[], 'data':[]}\n","with open('train.pickle', \"rb\") as fp:\n","  train = pickle.load(fp, encoding=\"latin-1\")\n","parse_pickle(train, \"train\")\n","\n","with open('val.pickle', \"rb\") as fp:\n","  val = pickle.load(fp, encoding=\"latin-1\")\n","parse_pickle(val, \"val\")"]},{"cell_type":"markdown","metadata":{"id":"U9RthrI0RLNE"},"source":["##データ拡張とデータセット作成\n","画像認識において「データ拡張」は汎化性能を上げる重要な役割を果たします。  \n","torchvision.transforms という PyTorch のサブライブラリを用いてデータ拡張を行います。  \n","また、transforms.Composeの中に記入することで、記入したtransformのコマンドを一度に実行することができます。\n","\n","今回は一般的に必要な  \n","\n","*  画像のテンソル化 ( transforms.ToTensor() )  \n","*  RGBの平均と標準偏差をそれぞれ0.5に設定する正規化 ( transforms.Nomalize())\n","\n","を行いました。\n","\n","Pytorchが提供しているその他のtransformのURLを記載しておくので、精度が上がる手法をそれぞれ試してみてください。  \n","データ拡張:https://pytorch.org/vision/stable/transforms.html"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"srr1_iuHTRkD"},"outputs":[],"source":["# データ拡張の設定\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","                                #もっと増やしてみてもいいかもしれません\n","                                ])"]},{"cell_type":"markdown","metadata":{"id":"TyOHJWQcXnPo"},"source":["次にバッチサイズとデータをまとめる処理になります。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ikxwktskLUzg"},"outputs":[],"source":["# バッチサイズの設定\n","batch_size = 25\n","\n","# データローダーの設定\n","trainset = torchvision.datasets.ImageFolder(root='train', transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n","\n","valset = torchvision.datasets.ImageFolder(root='val', transform=transform)\n","valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,shuffle=False, num_workers=2)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"]},{"cell_type":"markdown","metadata":{"id":"hDjU3M_spaBm"},"source":["データの量を確認します。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wfh6BJFfpX1i"},"outputs":[],"source":["print('学習データ:', len(trainset))\n","print('検証データ:', len(valset))"]},{"cell_type":"markdown","metadata":{"id":"xrT71I71X803"},"source":["##データの確認\n","ここで一度、データがどのようなものなのか確認してみましょう。"]},{"cell_type":"markdown","metadata":{"id":"WjLBQYkxWKM6"},"source":["# 6.転移学習"]},{"cell_type":"markdown","metadata":{"id":"akMSxWWXWqPN"},"source":["5章で作成したVGG11は、重みを１から作成して学習を始めました。  \n","発展的なモデルはモデルの容量が大きくなった分、１回の学習時間が非常に長くなってしまうという問題点があります。  \n","そのため、長期間学習を行わないと適した精度まで上がらないため、あまり実用的ではありません。  \n","そこで、事前にある程度学習が行われている事前学習済みモデルを利用する「転移学習」という手法を用います。\n","\n","PyTorchの公式サイトに掲載されているように、転移学習を実装したモデルを使ってみましょう。\n","\n","PyTorchの公式サイト：https://pytorch.org/vision/stable/models.html"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mGOc7w5-YOs7"},"outputs":[],"source":["# pytorch のライブラリーを利用して、事前学習の重みをロード済みのモデルインスタンスを作成する。\n","# なお、pretrained=True とすると事前学習モデルとなり、Falseとするとモデルのみが作成される。\n","net = torchvision.models.convnext_base(pretrained=True)\n","net"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-nXTKZ9GBaR6"},"outputs":[],"source":["# 分類器部分を cifar10 用に付け替える。\n","net.classifier[2] = nn.Linear(1024 ,out_features=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qhZ-_MeyY5qo"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jAjzQUSkY7qe"},"outputs":[],"source":["net = net.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"imZUi86hZAm2"},"outputs":[],"source":["from tqdm import tqdm\n","\n","# 学習エポックの設定\n","epoch_num = 50\n","\n","# 学習ループの設定\n","for epoch in tqdm(range(epoch_num)):  # エポックの進行度を表示するためにtqdmを使用\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0): # leave=Falseで内部のプログレスバーが完了後に消えるように設定\n","        inputs, labels = data\n","        optimizer.zero_grad()\n","\n","        # テンソルをGPUに移動\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        # forward + backward + optimize\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # 結果表示\n","        running_loss += loss.item()\n","        if i % 2000 == 1999:\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 2000))\n","            running_loss = 0.0\n","print('Finished Training')\n"]},{"cell_type":"markdown","metadata":{"id":"crkboDruZIln"},"source":["##結果のモデルを保存する\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hFWDKV3vZIlo"},"outputs":[],"source":["vgg_pre_weight_path = './vgg_pre_weight_path.pth'\n","torch.save(net.state_dict(), vgg_pre_weight_path)"]},{"cell_type":"markdown","metadata":{"id":"q0iBz9ClZIlo"},"source":["##結果を検証用データで確認する"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qKDO3IfFZIlp"},"outputs":[],"source":["net.load_state_dict(torch.load(vgg_pre_weight_path))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qgo9ap9_ZIlp"},"outputs":[],"source":["correct = 0\n","total = 0\n","# 勾配を記憶せず（学習せずに）に計算を行う\n","with torch.no_grad():\n","    for data in valloader:\n","        images, labels = data\n","\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","print('正解率 : %d %%' % (100 * correct / total))"]},{"cell_type":"markdown","metadata":{"id":"Hs_p7w3NpSR1"},"source":["## （参考）提出用データの作成の仕方\n","\n","上記のモデルでテスト用データを予測して提出用ファイルを出力するまでを\n","掲載してみました。\n","\n","実行してみましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vK1O3TCDz0NG"},"outputs":[],"source":["!wget 'https://drive.google.com/uc?export=download&id=1-T-luRcFf14qV_rR66B3groh8imA-8lo' -O test_data.pickle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-9nvdZN6IpqI"},"outputs":[],"source":["transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","with open('test_data.pickle', \"rb\") as fp:\n","  test = pickle.load(fp, encoding=\"latin-1\")\n","\n","for i in range(len(test['data'])):\n","  data = test[\"data\"][i]\n","  data = data.reshape(3, 32, 32)\n","  data = np.swapaxes(data, 0, 2)\n","  data = np.swapaxes(data, 0, 1)\n","  img = transform(data)\n","  img = torch.unsqueeze(img, 0)\n","  if i==0:\n","    images=img\n","  else:\n","    images = torch.cat([images, img])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pZd3xxzUqUKv"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","net.eval()\n","images = images.to(device)\n","with torch.no_grad():\n","    outputs = net(images)\n","    _, predictions = torch.max(outputs, 1)\n","print(predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eL8kUfB1NaxF"},"outputs":[],"source":["# pandasのDataFrame形式に変換し、CSV出力する\n","import pandas as pd\n","y_pred = pd.DataFrame(predictions.cpu(), columns=['number'])\n","y_pred.to_csv('y_pred.csv')\n","y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uGyLIzaOIty_"},"outputs":[],"source":["!wget 'https://drive.google.com/uc?export=download&id=1-UHqW8wgH46J-ltEdUfOX-DounUbZMAI' -O test_label.pickle\n","with open('test_label.pickle', \"rb\") as fp:\n","  test_label = pickle.load(fp, encoding=\"latin-1\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uUJSQCLtz5DP"},"outputs":[],"source":["labels = torch.tensor(test_label['label'])\n","correct = (predictions.cpu() == labels).sum().item()\n","assert len(predictions) == len(labels)\n","print( f\"正解率 : {100 * correct // len(labels)} %\" )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2dypK15Y1dCZ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1_tMfvGkgpGO_oup90_vFJCEVTM3vLcBI","timestamp":1647306872343},{"file_id":"1cNiukMLrtRM12FyR1UTJhFRjVujVED_i","timestamp":1645762178136},{"file_id":"15mMct028BgL47zx-ssEllmqob8dN2D3E","timestamp":1642562307537}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}